{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Cervical Cancer Risk Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRl189azYOzw",
        "colab_type": "text"
      },
      "source": [
        "###Cervical Cancer Risk Classification\n",
        "This project does the resampling and validating of the model choosen with an imbalanced data provided."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLoAcGu1dxvR",
        "colab_type": "code",
        "outputId": "305893ed-a50e-4ab1-8df5-6add1aae5417",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, recall_score, classification_report\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "df = pd.read_csv (\"/content/risk_factors_cervical_cancer.csv\")\n",
        "\n",
        "df['Number of sexual partners'].replace('?',df['Number of sexual partners'].mode()[0], inplace=True)\n",
        "df['First sexual intercourse'].replace('?',df['First sexual intercourse'].mode()[0], inplace=True)\n",
        "df['Num of pregnancies'].replace('?',df['Num of pregnancies'].mode()[0], inplace=True)\n",
        "df['Smokes'].replace('?',df['Smokes'].mode()[0], inplace=True)\n",
        "df['Smokes (years)'].replace('?',df['Smokes (years)'].mode()[0], inplace=True)\n",
        "df['Smokes (packs/year)'].replace('?',df['Smokes (packs/year)'].mode()[0], inplace=True)\n",
        "df['Hormonal Contraceptives'].replace('?',df['Hormonal Contraceptives'].mode()[0], inplace=True)\n",
        "df['Hormonal Contraceptives (years)'].replace('?',df['Hormonal Contraceptives (years)'].mode()[0], inplace=True)\n",
        "df['IUD'].replace('?',df['IUD'].mode()[0], inplace=True)\n",
        "df['IUD (years)'].replace('?',df['IUD (years)'].mode()[0], inplace=True)\n",
        "df['STDs'].replace('?',df['STDs'].mode()[0], inplace=True)\n",
        "df['STDs (number)'].replace('?',df['STDs (number)'].mode()[0], inplace=True)\n",
        "df['condylomatosis'].replace('?',df['condylomatosis'].mode()[0], inplace=True)\n",
        "df['cervical condylomatosis'].replace('?',df['cervical condylomatosis'].mode()[0], inplace=True)\n",
        "df['vaginal condylomatosis'].replace('?',df['vaginal condylomatosis'].mode()[0], inplace=True)\n",
        "df['vulvo-perineal condylomatosis'].replace('?',df['vulvo-perineal condylomatosis'].mode()[0], inplace=True)\n",
        "df['syphilis'].replace('?',df['syphilis'].mode()[0], inplace=True)\n",
        "df['pelvic inflammatory disease'].replace('?',df['pelvic inflammatory disease'].mode()[0], inplace=True)\n",
        "df['genital herpes'].replace('?',df['genital herpes'].mode()[0], inplace=True)\n",
        "df['molluscum contagiosum'].replace('?',df['molluscum contagiosum'].mode()[0], inplace=True)\n",
        "df['AIDS'].replace('?',df['AIDS'].mode()[0], inplace=True)\n",
        "df['HIV'].replace('?',df['HIV'].mode()[0], inplace=True)\n",
        "df['Hepatitis B'].replace('?',df['Hepatitis B'].mode()[0], inplace=True)\n",
        "df['HPV'].replace('?',df['HPV'].mode()[0], inplace=True)\n",
        "df[' Number of diagnosis'].replace('?',df[' Number of diagnosis'].mode()[0], inplace=True)\n",
        "\n",
        "df = df.drop('Time since first diagnosis',axis=1).dropna()\n",
        "df = df.drop('Time since last diagnosis',axis=1).dropna()\n",
        "#print (df.columns)\n",
        "\n",
        "print(df.columns[df.isin(['?']).any()])\n",
        "\n",
        "X = df.drop('Cancer', axis=1).dropna()\n",
        "\n",
        "y = df['Cancer'].dropna()\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
        "random_forest = RandomForestClassifier(n_estimators=500).fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "\n",
        "# Accuracy vs Recall\n",
        "print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))\n",
        "print('Recall score: ' + str(recall_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index([], dtype='object')\n",
            "Accuracy score: 0.9813953488372092\n",
            "Recall score: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       209\n",
            "           1       0.75      0.50      0.60         6\n",
            "\n",
            "    accuracy                           0.98       215\n",
            "   macro avg       0.87      0.75      0.80       215\n",
            "weighted avg       0.98      0.98      0.98       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4kL4_livfSrI",
        "colab_type": "text"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-F7yRNy4T2nD",
        "colab_type": "code",
        "outputId": "3cc8f2f6-6ab0-4fa4-e58b-60785a2872eb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        }
      },
      "source": [
        "# Checking the Accuracy and Recall with only two columns\n",
        "X = df.loc[:,['Smokes', 'Hormonal Contraceptives']]\n",
        "y = df['Cancer'].dropna()\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
        "random_forest = RandomForestClassifier(n_estimators=500).fit(X_train, y_train)\n",
        "y_pred = random_forest.predict(X_test)\n",
        "print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))\n",
        "print('Recall score: ' + str(recall_score(y_test, y_pred)))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.986046511627907\n",
            "Recall score: 0.0\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       212\n",
            "           1       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.99       215\n",
            "   macro avg       0.49      0.50      0.50       215\n",
            "weighted avg       0.97      0.99      0.98       215\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AyGL6gvZUQZU",
        "colab_type": "text"
      },
      "source": [
        "Resampling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBviIkK_UTac",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import the resampling package\n",
        "from sklearn.utils import resample\n",
        "\n",
        "# Split into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25)\n",
        "# Returning to one dataframe\n",
        "training_set = pd.concat([X_train, y_train], axis=1)\n",
        "# Separating classes\n",
        "cancer = training_set[training_set.Cancer == 1]\n",
        "not_cancer = training_set[training_set.Cancer == 0]\n",
        "#print('cancer:',cancer['Cancer'])\n",
        "#print('not_cancer:',not_cancer['Cancer'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lwfJ8uOCtV2Z",
        "colab_type": "text"
      },
      "source": [
        "Undersampling the Majority"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eX0Qi171tY7q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "3874bb64-9714-4c40-cc99-fa7701352fdd"
      },
      "source": [
        "# Undersampling the majority\n",
        "undersample = resample(not_cancer, \n",
        "                       replace=True, \n",
        "                       n_samples=len(cancer), #set the number of samples to equal the number of the minority class\n",
        "                       random_state=42)\n",
        "# Returning to new training set\n",
        "undersample_train = pd.concat([cancer, undersample])\n",
        "undersample_train.Cancer.value_counts(normalize=True)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.5\n",
              "0    0.5\n",
              "Name: Cancer, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6eUgJWJrtv5t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "outputId": "96e7cf70-82e5-4d0d-834f-f9e6dfa60ba4"
      },
      "source": [
        "# Testing on Random Forest classifier.\n",
        "\n",
        "# Separate undersampled data into X and y sets\n",
        "undersample_x_train = undersample_train.drop('Cancer', axis=1)\n",
        "undersample_y_train = undersample_train.Cancer\n",
        "\n",
        "# Fit model on undersampled data\n",
        "undersample_rf = RandomForestClassifier(n_estimators=500).fit(undersample_x_train, undersample_y_train)\n",
        "\n",
        "# Make predictions on test sets\n",
        "y_pred = random_forest.predict(X_test)\n",
        "print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))\n",
        "print('Average Recall score: ' + str(recall_score(y_test, y_pred, average='macro')))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.986046511627907\n",
            "Average Recall score: 0.5\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      1.00      0.99       212\n",
            "           1       0.00      0.00      0.00         3\n",
            "\n",
            "    accuracy                           0.99       215\n",
            "   macro avg       0.49      0.50      0.50       215\n",
            "weighted avg       0.97      0.99      0.98       215\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eRmujdjJuShE",
        "colab_type": "text"
      },
      "source": [
        "Oversampling the Minority"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZJgtfE_PuWGZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c6543f66-c177-4e39-a309-22b6fdd121b5"
      },
      "source": [
        "# Oversampling the minority\n",
        "oversample = resample(cancer, \n",
        "                       replace=True, \n",
        "                       n_samples=len(not_cancer), #set the number of samples to equal the number of the majority class\n",
        "                       random_state=42)\n",
        "\n",
        "# Returning to new training set\n",
        "oversample_train = pd.concat([not_cancer, oversample])\n",
        "oversample_train.Cancer.value_counts(normalize=True)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    0.5\n",
              "0    0.5\n",
              "Name: Cancer, dtype: float64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lJJ7GX-3uywO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "6dbc7c01-1fb6-40a6-cbc4-1ce4538d2689"
      },
      "source": [
        "# Separate oversampled data into X and y sets\n",
        "oversample_x_train = oversample_train.drop('Cancer', axis=1)\n",
        "oversample_y_train = oversample_train.Cancer\n",
        "\n",
        "# Fit model on oversampled data\n",
        "oversample_rf = RandomForestClassifier(n_estimators=500).fit(oversample_x_train, oversample_y_train)\n",
        "\n",
        "# Make predictions on test sets\n",
        "y_pred = oversample_rf.predict(X_test)\n",
        "print('Accuracy score: ' + str(accuracy_score(y_test, y_pred)))\n",
        "print('Average Recall score: ' + str(recall_score(y_test, y_pred, average='macro')))\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score: 0.6093023255813953\n",
            "Average Recall score: 0.4732704402515723\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.61      0.76       212\n",
            "           1       0.01      0.33      0.02         3\n",
            "\n",
            "    accuracy                           0.61       215\n",
            "   macro avg       0.50      0.47      0.39       215\n",
            "weighted avg       0.97      0.61      0.75       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nqz6aIg7vAxx",
        "colab_type": "text"
      },
      "source": [
        "SMOTE (synthetic minority oversampling technique)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nhLFVdy1vCHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 360
        },
        "outputId": "261a5d39-c8cf-4a2a-d4c8-a6daf4e82850"
      },
      "source": [
        "# Import the SMOTE package\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Synthesize minority class datapoints using SMOTE\n",
        "sm = SMOTE(random_state=42, sampling_strategy='minority')\n",
        "smote_x_train, smote_y_train = sm.fit_resample(X_train, y_train)\n",
        "\n",
        "# Separate into training and test sets\n",
        "smote_x_train = pd.DataFrame(smote_x_train, columns = X_train.columns)\n",
        "smote_y_train = pd.DataFrame(smote_y_train, columns = ['Cancer'])\n",
        "smote = RandomForestClassifier(n_estimators=1000).fit(smote_x_train, smote_y_train)\n",
        " \n",
        "# Predict on training set\n",
        "smote_preds = smote.predict(X_test)\n",
        "\n",
        "# Checking accuracy and recall\n",
        "print('Accuracy Score: ', accuracy_score(y_test, smote_preds),'\\n\\n')\n",
        "print('Averaged Recall Score: ', recall_score(y_test, smote_preds, average='macro'), '\\n\\n')\n",
        "    \n",
        "print(classification_report(y_test, smote_preds))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:10: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
            "  # Remove the CWD from sys.path while we load stuff.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score:  0.4232558139534884 \n",
            "\n",
            "\n",
            "Averaged Recall Score:  0.5432389937106918 \n",
            "\n",
            "\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.42      0.59       212\n",
            "           1       0.02      0.67      0.03         3\n",
            "\n",
            "    accuracy                           0.42       215\n",
            "   macro avg       0.50      0.54      0.31       215\n",
            "weighted avg       0.98      0.42      0.58       215\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}